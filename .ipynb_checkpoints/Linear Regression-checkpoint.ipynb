{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the weight of person using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Questions import Questions\n",
    "questions = Questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weight-height.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing the dataset\n",
    "\n",
    "- Checking the first rows\n",
    "- Looking for missing values\n",
    "- Looking for duplicates\n",
    "- Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've done some research and based on the values that are presented in the variables Height and Weight, they're using inches and pounds, respectively, as the unit of measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 10000 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Gender variable is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There aren't missing values in our dataset\n",
    "- The types of the variables are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There aren't duplicated rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn is great for exploratory data analysis because with few lines of code you can have meaningful plots that makes our life easier.\n",
    "\n",
    "- In this case for example, you can see that there is a linear relationship between the variables height and weight.\n",
    "\n",
    "- Another thing that you can see more clearly by looking at the density plot is that the gender is correlated with the variables height and weight. In the weight variable, for example, the mode is, approximately, 155 pounds for the women and 200 pounds for the men in our sample.\n",
    "\n",
    "So, the gender and the weight are variables that are suited for creating a linear regression model to predict the weight of a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transforming the dataset into two numpy arrays (X and y).\n",
    "- Splitting the dataset into training and test set\n",
    "- Transforming the variable Gender into a dummy / binary variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the X and y arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, usually, is a good practice to name matrices as uppercase letters and vectors as lower case letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the array X, just drop the target variable (Weight).\n",
    "# and assign the returned values to a new array\n",
    "\n",
    "X = df.drop('Weight', axis=1).values\n",
    "\n",
    "# The method .values() is used to transform a pandas series\n",
    "# or DataFrame into a numpy array.\n",
    "y = df['Weight'].values\n",
    "\n",
    "print('Matrix X: ', X, 'Shape:', X.shape, sep='\\n')\n",
    "print()\n",
    "print('Vector y: ', y, 'Shape:', y.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why you should split your dataset into a training and a test set?\n",
    "\n",
    "Dataset splitting is very important because of the concept of generalization. The model is only useful if it performs well into data that this model haven't seen yet.\n",
    "\n",
    "To understand this, I want you to imagine that you're studing for an exam. In order to be able to get a good score, you have to learn how to solve the problems, not memorize the answers of the questions that you've used to learn. The same is applied to machine learning models, we must guarantee that our model is learning the correlations of our data, not memorizing it, because in this way, our model will perform well in unseen data.\n",
    "\n",
    "But, how do we get to see how our model will perform well in unseen data, if we don't have this data yet?\n",
    "\n",
    "The people who have been working with data for a long time, has created a solution for this.\n",
    "\n",
    "Basically, you split your dataset into a training and test set. Your model is trained in the training set, and you use the parameters that have been learnt by the model to predict the values of the target variable using the test set as parameter.\n",
    "\n",
    "After that, you evaluate your model by comparing the predicted values with the observed values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random state is a very important parameter because it creates \n",
    "# a seed, that if some other person is trying\n",
    "# to reproduce your model, if the value of the random_state\n",
    "# is the same, all else being equal, he'll get the same results as you.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables\n",
    "\n",
    "Before creating a ML model, you must transform your categorical variables into numbers.\n",
    "\n",
    "In the case of this dataset, we're dealing with a nominal categorical variable with two categories. So, we must transform the variable into a binary variable.\n",
    "\n",
    "1. Pandas:\n",
    "    - pd.get_dummies(drop_first=True)\n",
    "2. Numpy Arrays:\n",
    "    - LabelEncoder()\n",
    "    - LabelBinarizer()\n",
    "    \n",
    "One important thing to say about data pre-processing, is that you have to be careful about Data Leakage. Data Leakage is when you some information outside of the training set is used in the model that is being trained.\n",
    "\n",
    "The Sklearn Library minimize this because in most of the preprocessing methods, there is two methods: \n",
    "- fit_transform()\n",
    "- transform()\n",
    "\n",
    "The fit_transform is used to save the parameters of the X_train and, at the same time, it transforms the X_train in the desired format. The transform method uses the parameters that were saved by the fit_transform method and transforms the test set into the same format as the X_train.\n",
    "\n",
    "In order to understand this, imagine that you have some missing values in a categorical variable and you want to use the sklearn object Imputer to impute those values with the mode of the variable. Sklearn will check the most frequent value in this variable on the training set and will transform the training set. Then, when you use the transform method on the test set, he will take the mode of training set and will replace the missing values of the test set using this value, even if the mode of the test set is different from the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "X_train[:, 0] = label.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = label.transform(X_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise One\n",
    "- Fit a linear regression model, make the predictions on the test set and calculate the root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your results\n",
    "questions.question_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the weight of woman with 75 inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your results\n",
    "questions.question_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the default parameters, create a KNN model and evaluate it using RMSE.\n",
    "- The documentation for creating a KNeighborsRegressor can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the MSE for the model, using KNNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code \n",
    "questions.question_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have seen in the documentation of KNeighborsRegressor, the default value for the number of neighbors is 5. What happens if you place the parameter n_neighbors=1 in the model?\n",
    "\n",
    "##### What is the performance of the model in the training set?\n",
    "\n",
    "       - Hint: Just replace the value of X_test for the value of X_train, to get the\n",
    "       predictions of the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to check if your answer is correct\n",
    "questions.question_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the performance of the model in the test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.question_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.question_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking your overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "questions.print_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
